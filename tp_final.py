# -*- coding: utf-8 -*-
"""TP final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/183ayobO_wSksOUVFpt4a14h6owW1rzGz

TP FINAL

El problema a resolver es la clasificación de frutas en diferentes categorías, utilizando imágenes como entrada.
"""

pip install keras-visualizer

!pip install tensorflow opencv-python matplotlib

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

print("Versión de TensorFlow:", tf.__version__)

# Lista de nombres de clases
class_names = ["apple", "banana", "cherry", "chiko", "grapes", "kiwi", "mango", "orange", "strawberry"]

# Directorio que contiene las carpetas de clases (apple, banana, etc.)
data_dir = 'ACA HAY QUE PONER EL LINK'

model = Sequential()

# Capas de convolución y pooling
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))

# Capa Flatten para aplanar los datos
model.add(Flatten())

# Capas densas
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(128, activation='relu'))
model.add(Dense(len(class_names), activation='softmax'))

# Compilar el modelo
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

"""Capa Conv2D (64 filtros, tamaño del kernel 3x3, activación ReLU):
Esta es la primera capa convolucional del modelo. La función Conv2D realiza convoluciones en la imagen de entrada utilizando 64 filtros de tamaño 3x3. La activación ReLU se aplica después de cada convolución para introducir no linealidades en la red.

Capa Conv2D (64 filtros, tamaño del kernel 3x3, activación ReLU):
Similar a la primera capa convolucional, esta capa realiza convoluciones adicionales con 64 filtros y activación ReLU.

Capa MaxPooling2D (tamaño de la ventana 2x2):
La capa de MaxPooling2D realiza un muestreo máximo para reducir las dimensiones espaciales de la representación, utilizando una ventana de 2x2. Esto ayuda a reducir la cantidad de parámetros y la carga computacional en la red.

Capa Conv2D (128 filtros, tamaño del kernel 3x3, activación ReLU):
Otra capa convolucional con 128 filtros y activación ReLU, permitiendo que la red capture patrones más complejos.

Capa Conv2D (128 filtros, tamaño del kernel 3x3, activación ReLU):
Una capa convolucional adicional, similar a la anterior, con 128 filtros y activación ReLU.

Capa MaxPooling2D (tamaño de la ventana 2x2):
Otra capa de MaxPooling2D que reduce las dimensiones espaciales antes de la siguiente capa convolucional.

Capa Conv2D (256 filtros, tamaño del kernel 3x3, activación ReLU):
Una tercera capa convolucional con 256 filtros y activación ReLU, aumentando la capacidad de representación de la red.

Capa MaxPooling2D (tamaño de la ventana 2x2):
Otra capa de MaxPooling2D que reduce aún más las dimensiones espaciales antes de la capa de aplanado.

Capa Flatten:
Esta capa aplana la salida de la capa anterior, convirtiendo los mapas de características en un vector unidimensional, necesario antes de pasar a las capas totalmente conectadas.

Capa Dropout (tasa de abandono de 0.5):
La capa Dropout apaga aleatoriamente el 50% de las unidades durante el entrenamiento para prevenir el sobreajuste.

Capa Dense (512 unidades, activación ReLU):
Una capa totalmente conectada con 512 unidades y activación ReLU, permitiendo la combinación lineal de características.

Capa Dense (5 unidades, activación softmax):
La capa de salida con 5 unidades (asumiendo un problema de clasificación con 5 clases) y activación softmax, que produce una distribución de probabilidad sobre las clases.
"""

datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

batch_size = 32
img_height, img_width = 224, 224

class_names = ["apple", "banana", "cherry", "chiko", "grapes", "kiwi", "mango", "orange", "strawberry"]

train_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(255, 255),
    batch_size=batch_size,
    class_mode='categorical',
    subset='training'
)

validation_generator = datagen.flow_from_directory(
    data_dir,
    target_size=(255, 255h),
    batch_size=batch_size,
    class_mode='categorical',
    subset='validation'
)

sample_images, sample_labels = next(train_generator)
plt.figure(figsize=(10, 10))
for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(sample_images[i])
    plt.title(class_names[np.argmax(sample_labels[i])])
    plt.axis("off")
plt.show()

predictions = model.predict(sample_images)
for i in range(9):
    print(f"Predicted: {class_names[np.argmax(predictions[i])]}, Actual: {class_names[np.argmax(sample_labels[i])]}")

history = model.fit(train_generator, epochs=10, validation_data=validation_generator)

from keras_visualizer import visualizer

visualizer(model, filename='model_architecture', format='png')